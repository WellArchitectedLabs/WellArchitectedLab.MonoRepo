apiVersion: apps/v1
kind: Deployment
#descriptions arounf the deployment
metadata:
  name: weather-forecast-frontend
  namespace: frontend
  annotations:
    sidecar.istio.io/inject: "true"
spec:
  selector:
    matchLabels:
      #should be used to identify the pod the deployment manages
      app: weather-forecast-frontend
  # deployment order replicaset controller to keep 3 instances of these pods always running
  replicas: 2
   # Add the rolling update strategy here
   # It is very imporant to add a rollout strategy, specially when add required anti affinity rules
   # required anti affinity rules will block creation of new pods on new nodes
   # in my case, I had three nodes each running one pod for high avaibaility
   # I then changed the image and performed a rolling update
   # the rolling update litterally blocked the new pods from beeing created because kubernetes cannot create pods on the same node as an existing one with the same name (please check the podAntyAffinity section)
   # We can customize the rolling update to be more or less strict with configuring the surge (number of extra pods that are created before they become the new truth about the deployment) and the maxUnavailable (which is the number of the concurrent unavailable pods)
  strategy:
    type: RollingUpdate
    rollingUpdate:
      # The surge is the number of extra pods that the rolling update creates
      # in order to apply a rollout.
      # Kubernetes blocks requests to the old pods and redirects them to new pods 
      # that are based on the new deployment (traffic redirection during rolling update)
      # If set to zero, there will be brief downtime since no new pods run in parallel
      maxSurge: 0
      # The number of unavailable pods at one time. This means that requests 
      # will be temporarily reduced during the update
      maxUnavailable: 1
  # pod definition section
  template:
    # metadata around the pod
    metadata:
      labels:
        app: weather-forecast-frontend
        # optional (nice to have)
        editor: vscode
        # necessary for kiali integration
        version: v1
    spec:
      # give pod 30 seconds to shut down after kube sends SIGTERM signal
      terminationGracePeriodSeconds: 30
      # Where will I tolerate my pods to run 
      # These do not restrict the pod from running on nodes that do not have the provided taint
      tolerations:
      - key: workload
        operator: 'Equal'
        value: 'weather-forecast'
        effect: 'NoSchedule'

      # Where will my pods will run, and in what node label
      # We should add a toleration because the user nodes are tainted and will be not schedule the pods if the taint is not provided
      nodeSelector:
        kubernetes.azure.com/mode: user
        
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: weather-forecast-frontend
              topologyKey: kubernetes.io/hostname
      containers:
      # can be multiple containers since one pod scan contain multiple containers
      - name: weather-forecast-frontend
        # test image from docker registry, provided by nginx project
        image: acrdevtshpwn.azurecr.io/weather-forecast-frontend:0.1.0-singleNodePool.1-55a41ad
        ports:
        - containerPort: 80
        imagePullPolicy: Always # Always pull latest version
        resources:
          requests:
            # node should have 128 megabytes available for pod to run into it
            # metrics are constantly sent from kubelet into metrics api (api server)
            # which updates etcd, 
            # kubernetes scheduler would then read the metrics and decide in which node the pod will be ran
            memory: "2Mi"
            # quarter of a CPU core is supposed to be allocated to this pod
            # this is used by kubernetes's scheduler for determining wether the pod can run into the node
            cpu: "20m"
          limits:
            memory: "1Gi"
            #1 core maimum allocated to each pod
            cpu: "1"
        #defining readiness and liveness probes
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
        volumeMounts:
          - name: weather-forecast-frontend-config-volume
            mountPath: '/usr/share/nginx/html/config'
            readOnly: true
      volumes:
        - name:  weather-forecast-frontend-config-volume
          configMap:
            name: weather-forecast-frontend-configmap