apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: grafana
  namespace: argocd
  labels:
    workload: operations
    isGrafana: "true"
  annotations:
    argocd.argoproj.io/sync-wave: "14" # We need the grafana server installed after database, otlp collector and Tempo tracing db
spec:
  project: default
  source:
    repoURL: https://grafana.github.io/helm-charts
    chart: grafana
    targetRevision: 7.3.9
    helm:
      values: |
        # Only one replica is sufficient for most production ready setups
        replicas: 1

        # Secure grafana admin credentials via existing kubernetes secret
        admin:
          existingSecret: grafana-secrets
          userKey: grafana-admin-user
          passwordKey: grafana-admin-password

        # Tolerate the grafana instance to run into the weather forecast node
        # Ideally, a separate node pool for monitoring (prometheus, grafana) and operations
        # Should be used.
        # We are hitting a quotas limitation so we are using only one node pool
        tolerations:
          - key: "workload"
            operator: "Equal"
            value: "weather-forecast"
            effect: "NoSchedule"
        nodeSelector:
            kubernetes.azure.com/mode: system

        # The datasource simply points to the prometheus service 
        # that is deployed via the prometheus argocd app
        # the kubernetes datasource points to current cluster
        datasources:
          datasources.yaml:
            apiVersion: 1
            datasources:
              # local prometheus service
              - name: Prometheus
                type: prometheus
                access: proxy
                url: http://prometheus-server-kube-pro-prometheus.monitoring.svc.cluster.local:9090
                isDefault: true
                editable: false
                uid: prometheus-uid
              # current kubernetes cluster
              - name: Kubernetes
                type: kubernetes
                access: proxy
                url: https://kubernetes.default.svc
                jsonData:
                  authType: serviceAccount
                  tlsSkipVerify: true
                editable: false
              - name: Tempo
                  type: tempo
                  access: proxy
                  url: http://tempo.monitoring.svc.cluster.local:3100
                  uid: tempo-uid
                  jsonData:
                    tracesToMetrics:
                      datasourceUid: prometheus-uid
                      spanStartTimeShift: "-1h"
                      spanEndTimeShift: "1h"
                      tags: 
                        - key: "service.name"
                          value: "service"
                        - key: "http.method"
                    # Service graph configuration
                    serviceMap:
                      datasourceUid: prometheus-service-graph
                    nodeGraph:
                      enabled: true
                    search:
                      hide: false
                    lokiSearch:
                      datasourceUid: ""
                  editable: false
                
                # Dedicated Prometheus datasource for service graphs
                - name: Prometheus-ServiceGraph
                  type: prometheus
                  access: proxy
                  url: http://prometheus-server-kube-pro-prometheus.monitoring.svc.cluster.local:9090
                  uid: prometheus-service-graph
                  editable: false
        
        # Use the deployed postgres instance to store grafana data

        # Load all secret keys as environment variables
        envFromSecret: grafana-secrets
        
        # Reference the environment variables for database configuration
        env:
          GF_DATABASE_TYPE: postgres
          GF_DATABASE_HOST: grafana-database-postgresql.monitoring.svc.cluster.local:5432
          GF_DATABASE_NAME: $__env{GF_POSTGRES_DB}
          GF_DATABASE_USER: $__env{GF_POSTGRES_USER}
          GF_DATABASE_PASSWORD: $__env{GF_POSTGRES_PASSWORD}
          GF_DATABASE_SSL_MODE: disable
        
        # It is important that grafana database is persisted
        # Otherwise, dashboards and data will be reset on cluster restart or any event happening in the nodes
        persistence:
          type: pvc
          enabled: true
          storageClassName: managed-csi
          # Makes sure mvcs are deployed with the right access modes
          accessModes:
            - ReadWriteOnce
          size: 10Gi

  destination:
    server: https://kubernetes.default.svc
    namespace: monitoring
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
    retry:
      limit: 5
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 3m